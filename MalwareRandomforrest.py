#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Mar 25 13:52:07 2023

@author: oscarmccabe
The functions used for the end solution are main and reducedMultClass, other functions were used when 
tryign to figure out the optimal solution. There is a breif explanation as to why i didn't use the other 
methods above the functions

Code was initally based off the example shown in the week 7 tutorial 
"""

# Import needed modules for random forrest, confusion matrix and splitting the data 

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, zero_one_loss, classification_report, accuracy_score, RocCurveDisplay, precision_recall_curve, average_precision_score, PrecisionRecallDisplay, roc_curve
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn import svm
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import label_binarize
import seaborn
import matplotlib.pyplot as plt 
import numpy as np

def main():
    #Import the Malware CSV
    
    print("Loading raw data")
    
    raw_data = pd.read_csv('Obfuscated-MalMem2022.csv')
    
    
    #EDA
    #View the first five collumns
    print(raw_data.head(5))
    #View the last five values 
    print(raw_data.tail(5))
    #View the information of each Column
    print(raw_data.info(verbose=True))
    print(raw_data.describe())
    #Generate inital Heatmap
    plt.figure(figsize=(40, 40))
    seaborn.heatmap(raw_data.corr(), annot = True)
    print("Null values")
    # No null values but found zeros so dropped them 
    print(raw_data.isnull().sum())
    refined_raw_data = raw_data.drop(columns = ['pslist.nprocs64bit', 'handles.nport', 'svcscan.interactive_process_services', 'pslist.nprocs64bit', 'handles.nport', 'svcscan.interactive_process_services', 'callbacks.nanonymous', 'callbacks.ngeneric',
                                                'psxview.not_in_eprocess_pool_false_avg', 'psxview.not_in_eprocess_pool', 'callbacks.ncallbacks', 'handles.nsection'])
    print(refined_raw_data.Class.value_counts())
    #Generate Heat Map of refined dataset
    plt.figure(figsize=(40, 40))
    seaborn.heatmap(refined_raw_data.corr(), annot = True)
    
    plt.show()
    #BinaryClassification(refined_raw_data)
    #MultiClass(refined_raw_data)
    reducedMultiClass(refined_raw_data)     #Commented out calls are for other algorithms used, reduced mulit class is the best performer 
    #NeuralNet(refined_raw_data)
    #SVM(refined_raw_data)

"""
Binary Classification overfitted to the point where both Training and Testing scores were 100%
decided not to use this method for submission
"""

def BinaryClassification(refined_raw_data):
    #Binary Classification 
    binaryClassData = refined_raw_data.drop(columns=['Category'])
    features = binaryClassData.iloc[:,:binaryClassData.shape[1]-1]
    labels = binaryClassData.iloc[:,binaryClassData.shape[1]-1:]
    
    labels = labels.values.ravel()
    
    df = pd.DataFrame(features)
    
    X_train, X_test, y_train, y_test = train_test_split(df, labels, train_size=0.7, test_size=0.3)
    print ("X_train, y_train:", X_train.shape, y_train.shape)
    print ("X_test, y_test:", X_test.shape, y_test.shape)
    
    print("Training Model")
    
    clf = RandomForestClassifier(max_depth=2, n_estimators=10,
        min_samples_split=3, max_leaf_nodes=5,
        random_state=2)
    trainedModel = clf.fit(X_train, y_train)
    print("Score: ", trainedModel.score(X_train, y_train))
    
    print("Predicting")
    
    y_pred = clf.predict(X_test)
    results = confusion_matrix(y_test, y_pred)
    error = zero_one_loss(y_test, y_pred)
    print("Confusion Matrix:\n", results)
    print("Error: ", error)
    print(classification_report(y_test, y_pred))
"""
SVM performed terribly, was wrong for the task, wasn't used in the final submission'
"""
def SVM(refined_raw_data):
    refined_raw_data = refined_raw_data.drop(columns=['Class'])
    refined_raw_data = refined_raw_data.loc[refined_raw_data["Category"] != 'Benign']
    #seaborn.pairplot(refined_raw_data)
    Category = refined_raw_data.iloc[:, 0]
    print(Category.value_counts())
    
    for item in Category:
        if item != 'Benign' or item != 'Ransomware' or item != 'Spyware' or item!= 'Trojan':
            splitItem = item.split('-')
            refinedItem = splitItem[0] #+ splitItem[1]
            #refined_raw_data.replace(to_replace=item, value=refinedItem)
            refined_raw_data['Category'] = refined_raw_data['Category'].replace([item], refinedItem)
    newCategory = refined_raw_data.iloc[:, 0]
    minData = refined_raw_data['Category'].value_counts().min()
    print(minData)
    print(newCategory.value_counts())
    balancedData = []
    for Cat in refined_raw_data['Category'].value_counts().index:
        samples = refined_raw_data[refined_raw_data['Category'] == Cat]
        samples = samples.sample(n=minData, random_state = 42)
        balancedData.append(samples)
    balancedData = pd.concat(balancedData).sample(frac=1, random_state=42)
    features = balancedData.iloc[:, balancedData.columns != 'Category']
    
    labels = balancedData.iloc[:, balancedData.columns == 'Category'].values.ravel()
    print(balancedData.iloc[:, balancedData.columns == 'Category'].value_counts())
    df = pd.DataFrame(features)
    X_train, X_test, y_train, y_test = train_test_split(df, labels, train_size=0.7, test_size=0.3, random_state=2022)
    print ("X_train, y_train:", X_train.shape, y_train.shape)
    print ("X_test, y_test:", X_test.shape, y_test.shape)
    #keyfold cross val 
    print("Training Model")
    clf = svm.SVC(decision_function_shape='ovo', degree=10, kernel='poly')
    trainedModel = clf.fit(X_train, y_train)
    print("Score: ", trainedModel.score(X_train, y_train))
    
    print("Predicting")
    
    y_pred = clf.predict(X_test)
    results = confusion_matrix(y_test, y_pred)
    #acc = accuracy_score(y_test, y_pred)
    error = zero_one_loss(y_test, y_pred)
    print("Confusion Matrix:\n", results)
    print("Error: ", error)
    print(classification_report(y_test, y_pred))

"""
Neural Network performed worse than random forest so was not used for the submission 
"""
def NeuralNet(refined_raw_data):
    refined_raw_data = refined_raw_data.drop(columns=['Class'])
    refined_raw_data = refined_raw_data.loc[refined_raw_data["Category"] != 'Benign']
    Category = refined_raw_data.iloc[:, 0]
    print(Category.value_counts())
    
    for item in Category:
        if item != 'Benign' or item != 'Ransomware' or item != 'Spyware' or item!= 'Trojan':
            splitItem = item.split('-')
            refinedItem = splitItem[0] #+ splitItem[1]
            #refined_raw_data.replace(to_replace=item, value=refinedItem)
            refined_raw_data['Category'] = refined_raw_data['Category'].replace([item], refinedItem)
    newCategory = refined_raw_data.iloc[:, 0]
    minData = refined_raw_data['Category'].value_counts().min()
    print(minData)
    print(newCategory.value_counts())
    balancedData = []
    for Cat in refined_raw_data['Category'].value_counts().index:
        samples = refined_raw_data[refined_raw_data['Category'] == Cat]
        samples = samples.sample(n=minData, random_state = 42)
        balancedData.append(samples)
    balancedData = pd.concat(balancedData).sample(frac=1, random_state=42)
    features = balancedData.iloc[:, balancedData.columns != 'Category']
    
    labels = balancedData.iloc[:, balancedData.columns == 'Category'].values.ravel()
    print(balancedData.iloc[:, balancedData.columns == 'Category'].value_counts())
    df = pd.DataFrame(features)
    X_train, X_test, y_train, y_test = train_test_split(df, labels, train_size=0.7, test_size=0.3, random_state=2022)
    print ("X_train, y_train:", X_train.shape, y_train.shape)
    print ("X_test, y_test:", X_test.shape, y_test.shape)
    #keyfold cross val 
    print("Training Model")
    clf= MLPClassifier(hidden_layer_sizes=(300,), activation='tanh', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='adaptive', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=True, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=20)
    trainedModel = clf.fit(X_train, y_train)
    print("Score: ", trainedModel.score(X_train, y_train))
    
    print("Predicting")
    
    y_pred = clf.predict(X_test)
    results = confusion_matrix(y_test, y_pred)
    acc = accuracy_score(y_test, y_pred)
    error = zero_one_loss(y_test, y_pred)
    print("Confusion Matrix:\n", results)
    print("Error: ", error)
    print(classification_report(y_test, y_pred))
    print("accuracy", acc)
    
"""
This function is the best performing soloution and the one to be used for the video and the report
It performs a multiclass classification with random forest to identify either Ransomware, Spyware or Trojan
from the dataset
"""    
def reducedMultiClass(refined_raw_data):
    """
    Droping the class column in the dataset and renaming the data in the category columns 
    
    """
    refined_raw_data = refined_raw_data.drop(columns=['Class'])
    refined_raw_data = refined_raw_data.loc[refined_raw_data["Category"] != 'Benign']
    Category = refined_raw_data.iloc[:, 0]
    print(Category.value_counts())
    
    for item in Category:
        if item != 'Benign' or item != 'Ransomware' or item != 'Spyware' or item!= 'Trojan':
            splitItem = item.split('-')
            refinedItem = splitItem[0] 
            refined_raw_data['Category'] = refined_raw_data['Category'].replace([item], refinedItem)
    newCategory = refined_raw_data.iloc[:, 0]
    """
    Randomly Selects one example from each category and stores them in a seperate dataframe.
    examples are also dropped from the dataframe used in the test train split.
    The dataframe created is used for the three unique inputs required in the video demo
    """
    finaldf = pd.DataFrame()
    iterList = ['Ransomware', 'Spyware', 'Trojan']
    for iter in iterList:
        tobeadded = refined_raw_data.loc[refined_raw_data['Category'] == iter]
        tobeadded = tobeadded.sample()
        tempdf = pd.DataFrame(tobeadded)
        print(tobeadded.index.tolist())
        refined_raw_data = refined_raw_data.drop(tobeadded.index.tolist()[0])
        finaldf = pd.concat([finaldf, tempdf], ignore_index=True)
    finaldf = finaldf.drop(columns=['Category'])
    print(finaldf)
    
    """
    Balancing the dataset as there are more Spyware and Ransomware examples than Trojan
    Makes use of random state to remove examples from the dataset randomly 
    """
    minData = refined_raw_data['Category'].value_counts().min()
    print(minData)
    print(newCategory.value_counts())
    balancedData = []
    for Cat in refined_raw_data['Category'].value_counts().index:
        samples = refined_raw_data[refined_raw_data['Category'] == Cat]
        samples = samples.sample(n=minData, random_state = 42)
        balancedData.append(samples)
    balancedData = pd.concat(balancedData).sample(frac=1, random_state=42)
    features = balancedData.iloc[:, balancedData.columns != 'Category']
    """
    Binarizing the labels so the script can visualise the results once the model is predicted
    """
    labels = balancedData.iloc[:, balancedData.columns == 'Category'].values.ravel()
    Y = label_binarize(labels, classes = ['Ransomware', 'Spyware', 'Trojan'])
    n_classes = Y.shape[1]
    print(Y)
    print(balancedData.iloc[:, balancedData.columns == 'Category'].value_counts())
    df = pd.DataFrame(features)
    #Splitting the data into training and testuing 
    X_train, X_test, y_train, y_test = train_test_split(df, Y, train_size=0.8, test_size=0.2, random_state=2022)
    print ("X_train, y_train:", X_train.shape, y_train.shape)
    print ("X_test, y_test:", X_test.shape, y_test.shape)
    """
    Training the model. Hyperparameters are tuned to try and reduce overfitting 
    """
    print("Training Model")
    clf =OneVsRestClassifier(RandomForestClassifier(max_depth=15, n_estimators=80,
        min_samples_split=10, max_leaf_nodes=None,
        random_state=12, max_features=18))     
    trainedModel = clf.fit(X_train, y_train)
    pred_prob = clf.predict_proba(X_test)
    print("Score: ", trainedModel.score(X_train, y_train))
    
    print("Predicting")
    """
    predicting with the test data and generating zero one loss and classification report 
    """
    y_pred = clf.predict(X_test)
    error = zero_one_loss(y_test, y_pred)
    print("Error: ", error)
    print(classification_report(y_test, y_pred))
    
    """
    Generating Confusion Matrix 
    """
    
    matrixLables = ['Ransomware', 'Spyware', 'Trojan']
    ax = plt.subplot()
    cm = confusion_matrix(np.asarray(y_test).argmax(axis=1), np.asarray(y_pred).argmax(axis=1))
    seaborn.heatmap(cm, annot=True, fmt='g', ax=ax);
    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); 
    ax.set_title('Confusion Matrix'); 
    ax.xaxis.set_ticklabels(matrixLables); ax.yaxis.set_ticklabels(matrixLables);
    plt.show()

    """
    Generating Precision Recall Curve
    """
    precision = dict()
    recall = dict()
    for i in range(n_classes):
        precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],
                                                        pred_prob[:, i])
        plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))
    
    plt.xlabel("recall")
    plt.ylabel("precision")
    plt.legend(loc="best")
    plt.title("precision vs. recall curve")
    plt.show()
    
    """
    Generating ROC Curve 
    """

    fpr = dict()
    tpr = dict()

    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test[:, i],pred_prob[:, i])
        plt.plot(fpr[i], tpr[i], lw=2, label='class {}'.format(i))

    plt.xlabel("false positive rate")
    plt.ylabel("true positive rate")
    plt.legend(loc="best")
    plt.title("ROC curve")
    plt.show()
    
    
    """
    Predictions from reserved dataset
    """
    print('\nPredictions for the three unique iputs\n')
    y_reserved = clf.predict(finaldf)
    y_reserved_probs = clf.predict_proba(finaldf)
    print('Probability that each example is either \nRansomware, Spyware or Trojan (in that order)')
    print(y_reserved_probs[:,0])
    print(y_reserved_probs[:,1])
    print(y_reserved_probs[:,2])
    print('\n\nFinal Decision for Malware Class for each example \nRansomware, Spyware, Trojan\n', y_reserved)

"""
Less polished version of what was used for the final solution.
Under performs due to the fact that it tries to identify malware types with the individual hashes
meaning that there are only one or two examples of each, hence why the final soluiton renames the 
category column in the dataset
"""
def MultiClass(refined_raw_data):
    print("Performing Mulit Class ")
    MultiClassData = refined_raw_data.drop(columns=['Class'])
    print(MultiClassData.Category.value_counts())
    features = MultiClassData.iloc[:, MultiClassData.columns != 'Category']
    labels = MultiClassData.iloc[:, 0]
    labels = labels.values.ravel()
    df = pd.DataFrame(features)
    X_train, X_test, y_train, y_test = train_test_split(df, labels, train_size=0.8, test_size=0.2)
    print ("X_train, y_train:", X_train.shape, y_train.shape)
    print ("X_test, y_test:", X_test.shape, y_test.shape)
    
    print("Training Model")
    
    #clf = RandomForestClassifier(max_depth=2, n_estimators=30,
    #    min_samples_split=3, max_leaf_nodes=5,
    #    random_state=3)
    
    clf = RandomForestClassifier(max_depth=4, n_jobs=-1, random_state=3, n_estimators=100)
    trainedModel = clf.fit(X_train, y_train)
    print("Score: ", trainedModel.score(X_train, y_train))
    
    print("Predicting")
    
    y_pred = clf.predict(X_test)
    results = confusion_matrix(y_test, y_pred)
    error = zero_one_loss(y_test, y_pred)
    print("Confusion Matrix:\n", results)
    print("Error: ", error)
    #print(classification_report(y_test, y_pred))

if __name__ == '__main__':
    main()



